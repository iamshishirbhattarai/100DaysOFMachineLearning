{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "391c6f6f-2a48-43c0-8db5-c0a626882719",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053afa9a-b2e2-4e07-bfde-71e193a13d53",
   "metadata": {},
   "source": [
    "### Knowing how gradient boosting works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf87eed5-52b7-4ed1-b364-80f5f64909c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17653689, 0.37193428, 0.24815821])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Understanding how does Gradient Boosting actually works\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3 * X[:,0] ** 2 + 0.05 - np.random.randn(100)\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth = 2, random_state = 42)\n",
    "tree_reg1.fit(X, y)\n",
    "\n",
    "#Now calculating the residuals of tree_reg1 as \n",
    "y2 = y - tree_reg1.predict(X)\n",
    "\n",
    "#using y2 as target variable and training the another model\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth = 2, random_state = 42)\n",
    "tree_reg2.fit(X, y2)\n",
    "\n",
    "#Again calculating the residuals of tree_reg2 as\n",
    "y3 = y2 - tree_reg2.predict(X)\n",
    "\n",
    "#using y3 as new target variable and training another model\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth = 2, random_state = 42)\n",
    "tree_reg3.fit(X, y3)\n",
    "\n",
    "#assuming a new X\n",
    "X_new = np.array([[-0.4], [0.], [0.5]])\n",
    "\n",
    "sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc76fea0-465c-4326-8b56-1a00dd34818f",
   "metadata": {},
   "source": [
    "### Direct Implementation through GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cc18449-7717-494f-96ff-646f8fa1b630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17653689, 0.37193428, 0.24815821])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators = 3, learning_rate = 1.0, random_state = 42)\n",
    "gbrt.fit(X, y)\n",
    "gbrt.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53382737-3873-4cf8-8061-2fd727983602",
   "metadata": {},
   "source": [
    "### Finding Optimal Number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f570770-8771-4722-acc8-9c8675b4129b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt_new = GradientBoostingRegressor(max_depth = 2, n_estimators = 500, learning_rate = 0.01, random_state = 42,\n",
    "                                    n_iter_no_change = 8)\n",
    "gbrt_new.fit(X, y)\n",
    "\n",
    "gbrt_new.n_estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf51f9-334a-4b3d-ac9f-44b063b7118e",
   "metadata": {},
   "source": [
    "So, It stopped after 13 estimators as it doesn't see any improvements in the model after that in the last 8 trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861e923-8088-42de-9ada-11763eaaab58",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c23135e6-64b5-48e2-bbba-30f287032fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X,y = make_moons(n_samples = 500, noise = 0.30, random_state = 42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators = [\n",
    "        ('lr', LogisticRegression(random_state = 42)),\n",
    "        ('rf', RandomForestClassifier(random_state = 42)),\n",
    "        ('svc', SVC(probability = True, random_state = 42))\n",
    "    ],\n",
    "    final_estimator = RandomForestClassifier(random_state = 43),\n",
    "    cv = 5\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_stack_pred = stacking_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_stack_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
