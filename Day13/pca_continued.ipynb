{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db08571c-cfc5-4188-85ed-9b5d15166ef1",
   "metadata": {},
   "source": [
    "## PCA continued .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76385f66-eb41-4bb4-a101-4a4277d3c547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "mnist = fetch_openml('mnist_784', as_frame = False)\n",
    "X_train, y_train = mnist.data[:60_000], mnist.target[:60_000]\n",
    "X_test, y_test = mnist.data[60_000:], mnist.target[60_000:]\n",
    "\n",
    "pca = PCA(n_components = 0.95)\n",
    "X_reduced = pca.fit_transform(X_train)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3377e40-0ed1-4976-bf51-41abe603409d",
   "metadata": {},
   "source": [
    "This states we need **154** features to preserve variance by 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99dba5c-6585-42e7-a5d3-c4a5f83541f9",
   "metadata": {},
   "source": [
    "### Finding Best no. of components with Radomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42753ded-f76d-4bb6-9910-fa065d02c59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestclassifier__n_estimators': 465, 'pca__n_components': 23}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "clf = make_pipeline(PCA(random_state=42), RandomForestClassifier(random_state=42))\n",
    "param_dist = {\n",
    "    'pca__n_components' : np.arange(10,80),\n",
    "    'randomforestclassifier__n_estimators' : np.arange(50, 500)\n",
    "}\n",
    "rand_search = RandomizedSearchCV(clf, param_dist, n_iter=10, cv=3, random_state=42)\n",
    "rand_search.fit(X_train[:1000], y_train[:1000])\n",
    "rand_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf24afd-6037-405e-b7b8-ee424d3e0622",
   "metadata": {},
   "source": [
    "So, the 784 dimensional data is reduced to 23 components using PCA. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
